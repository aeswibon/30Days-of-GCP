## Contents
1. [Introduction to APIs in Google](#Introduction%20to%20APIs%20in%20Google)
2. [Extract, Analyze, and Translate Text from Images with the Cloud ML APIs](#Extract,%20Analyze,%20and%20Translate%20Text%20from%20Images%20with%20the%20Cloud%20ML%20APIs)
---
#### Introduction to APIs in Google
- HTTP protocol and request methods
	- **GET** request method is used by a client to fetch data from a server. If the requested resource is found on the server, it will then be sent back to the client.
	- **PUT** method replaces existing data or creates data if it does not exist. If you use PUT many times, it will have no effect — there will only be one copy of the dataset on the server.
	-  **POST** method is used primarily to create new resources. Using POST many times will add data in multiple places on the server. It is recommended to use PUT to update resources and POST to create new resources.
	- **DELETE** method will remove data or resources specified by the client on a server.
- **Endpoints** are access points to data or computing resources hosted on a server and they take the form of an HTTP URI. Endpoints are added to an API's base URL (e.g. `http://example.com`) to create a path to a specific resource or container of resources.
- APIs that utilize the HTTP protocol, request methods, and endpoints are referred to as **RESTful APIs**.
- RESTful APIs use either XML or JSON (JavaScript Object Notation) as file formats for data held in the body of an HTTP request method.
- JSON supports the following data types:
	-   **Numbers**: all types — no distinction between integers and floating point values.
	-   **Strings**: text enclosed in quotes.
	-  **Booleans**: True or False values.
	-  **Arrays**: a list of elements grouped by similar type.
	-   **Null**: an "empty" value.
- Create a bucket with the Cloud Storage JSON/REST API
	```bash
	# input the details for bucket in values.json
	cat > values.json << EOF
	{  "name": "<YOUR_BUCKET_NAME>",
   		"location": "us",
   		"storageClass": "multi_regional"
	}
	EOF
	#
	# export the OAUTH_TOKEN
	export OAUTH2_TOKEN=<TOKEN>
	#
	# export the PROJECT_ID
	export PROJECT_ID=<YOUR_PROJECT_ID>
	#
	# create a cloud storage bucket
	curl -X POST --data-binary @values.json -H "Authorization: Bearer $OAUTH2_TOKEN" -H "Content-Type: application/json" "https://www.googleapis.com/storage/v1/b?project=$PROJECT_ID"
	#
	# to get the path of the object you want to upload, use this
	realpath <OBJECT_NAME_WITH_EXTENSION>
	#
	# export the path of the object you want to upload
	export OBJECT=<DEMO_IMAGE_PATH>
	#
	# export the BUCKET_NAME
	export BUCKET_NAME=<BUCKET_NAME>
	#
	# upload the object in the bucket
	curl -X POST --data-binary @$OBJECT -H "Authorization: Bearer $OAUTH2_TOKEN" -H "Content-Type: image/png"
	"https://www.googleapis.com/upload/storage/v1/b/$BUCKET_NAME/o?uploadType=media&name=<NAME_OF_THE_OBJECT>"
	```
___
#### Extract, Analyze, and Translate Text from Images with the Cloud ML APIs
```bash
# export the bucket name
export BUCKET_NAME=<NAME>
#
# create a fine-grained with unchecked prevent public access
gsutil mb --pap=unspecified -b off gs://$BUCKET_NAME
#
# downloadind the required file
wget --output-document sign.jpg https://cdn.qwiklabs.com/cBoI5P4dZ6k%2FAr5Mv7eME%2F0fCb4G6nIGB0odCXzpEa4%3D
#
# copy the file to the bucket
gsutil cp sign.jpg gs://$BUCKET_NAME
#
# adding the permmission to the file 
gsutil acl ch -u AllUsers:R gs://$BUCKET_NAME/sign.jpg
#
# sending text from image to the translation api
cat > translation-request.json << EOF 
{
  "q": "your_text_here",
  "target": "en"
}
EOF
#
# change the value of 'q' to something else
STR=$(jq .responses[0].textAnnotations[0].description ocr-response.json) && STR="${STR//\"}" && sed -i "s|your_text_here|$STR|g" translation-request.json
#
# post the request
curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" -s -X POST -H "Content-Type: application/json" --data-binary @nl-request.json
#
# save the response in a file
curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" -s -X POST -H "Content-Type: application/json" --data-binary @nl-request.json -o nl-response.json
```
---
#### Challenge Lab
- Step 1:
	```bash
	# start
	# export the project id
	# export PROJECT_ID=<your_project_name>
	export PROJECT_ID=qwiklabs-gcp-02-a977a3e503e8
	#
	# export the bucket name
	export BUCKET_NAME=$PROJECT_ID
	#
	# create a service account
	gcloud iam service-accounts create gse-acc --display-name=gse-acc
	#
	# bind the BigQuery Admin
	gcloud projects add-iam-policy-binding $PROJECT_ID --member=serviceAccount:gse-acc@$PROJECT_ID.iam.gserviceaccount.com --role=roles/bigquery.admin
	#
	# bind the Cloud Storage Admin
	gcloud projects add-iam-policy-binding $PROJECT_ID --member=serviceAccount:gse-acc@$PROJECT_ID.iam.gserviceaccount.com --role=roles/storage.admin
	#
	# end
	
	```
- Step 2:
	```bash
	# start
	# create the credential file
	gcloud iam service-accounts keys create key.json --iam-account=gse-acc@$PROJECT_ID.iam.gserviceaccount.com
	#
	# export the credentials
	export GOOGLE_APPLICATION_CREDENTIALS=key.json
	#
	# end
	
	```
- Step 3:
	```bash
	# start
	# copy the analyze-images.py into cloud shell
	gsutil cp gs://$PROJECT_ID/analyze-images.py .
	#
	# end
	
	```
	```py
	# in analyze-iamges.py
	# add on line 56
	# after these lines
	# TBD: Create a Vision API image object called image_object
	# Ref: https://googleapis.dev/python/vision/latest/gapic/v1/types.html#google.cloud.vision_v1.types.Image
	image_object = vision.Image(content=file_content)
	#
	# add on line 61
	# after these lines
	# TBD: Detect text in the image and save the response data into an object called response
    # Ref: https://googleapis.dev/python/vision/latest/gapic/v1/api.html#google.cloud.vision_v1.ImageAnnotatorClient.document
	response = vision_client.document_text_detection(image=image_object)
	```
	```bash
	python3 analyze-images.py $PROJECT_ID $BUCKET_NAME
	```

- Step 4:
	```py
	# in analyze-iamges.py
	# on line 85
	# after these lines
	# Set the target_language locale to 'en')
	# from google.cloud import translate_v2 as translate
	translation = translate_client.translate(desc, target_language='en')
	# uncomment this line 
	errors = bq_client.insert_rows(table, rows_for_bq)
	```
	The whole python script will look like this:
	```py
	# Dataset: image_classification_dataset
	# Table name: image_text_detail
	import os
	import sys

	# Import Google Cloud Library modules
	from google.cloud import storage, bigquery, language, vision,translate_v2
	client = vision.ImageAnnotatorClient()

	if ('GOOGLE_APPLICATION_CREDENTIALS' in os.environ):
		if (not os.path.exists(os.environ['GOOGLE_APPLICATION_CREDENTIALS'])):
			print ("The GOOGLE_APPLICATION_CREDENTIALS file does not exist.\n")
			exit()
	else:
		print ("The GOOGLE_APPLICATION_CREDENTIALS environment variable is not defined.\n")
		exit()

	if len(sys.argv)<3:
		print('You must provide parameters for the Google Cloud project ID and Storage bucket')
		print ('python3 '+sys.argv[0]+ '[PROJECT_NAME] [BUCKET_NAME]')
		exit()

	project_name = sys.argv[1]
	bucket_name = sys.argv[2]

	# Set up our GCS, BigQuery, and Natural Language clients
	storage_client = storage.Client()
	bq_client = bigquery.Client(project=project_name)
	nl_client = language.LanguageServiceClient()

	# Set up client objects for the vision and translate_v2 API Libraries
	vision_client = vision.ImageAnnotatorClient()
	translate_client = translate_v2.Client()

	# Setup the BigQuery dataset and table objects
	dataset_ref = bq_client.dataset('image_classification_dataset')
	dataset = bigquery.Dataset(dataset_ref)
	table_ref = dataset.table('image_text_detail')
	table = bq_client.get_table(table_ref)

	# Create an array to store results data to be inserted into the BigQuery table
	rows_for_bq = []

	# Get a list of the files in the Cloud Storage Bucket
	files = storage_client.bucket(bucket_name).list_blobs()
	bucket = storage_client.bucket(bucket_name)

	print('Processing image files from GCS. This will take a few minutes..')

	# Process files from Cloud Storage and save the result to send to BigQuery
	for file in files:    
		if file.name.endswith('jpg') or  file.name.endswith('png'):
			file_content = file.download_as_string()

			# TBD: Create a Vision API image object called image_object
			# Ref: https://googleapis.dev/python/vision/latest/gapic/v1/types.html#google.cloud.vision_v1.types.Image
			image_object = vision.Image(content=file_content)

			# TBD: Detect text in the image and save the response data into an object called response
			# Ref: https://googleapis.dev/python/vision/latest/gapic/v1/api.html#google.cloud.vision_v1.ImageAnnotatorClient.document
			response = vision_client.document_text_detection(image=image_object)_text_detection

			# Save the text content found by the vision API into a variable called text_data
			text_data = response.text_annotations[0].description

			# Save the text detection response data in <filename>.txt to cloud storage
			file_name = file.name.split('.')[0] + '.txt'
			blob = bucket.blob(file_name)
			# Upload the contents of the text_data string variable to the Cloud Storage file 
			blob.upload_from_string(text_data, content_type='text/plain')

			# Extract the description and locale data from the response file
			# into variables called desc and locale
			# using response object properties e.g. response.text_annotations[0].description
			desc = response.text_annotations[0].description
			locale = response.text_annotations[0].locale

			# if the locale is English (en) save the description as the translated_txt
			if locale == 'en':
				translated_text = desc
			else:
				# TBD: For non EN locales pass the description data to the translation API
				# ref: https://googleapis.dev/python/translation/latest/client.html#google.cloud.translate_v2.client.Client.translate
				# Set the target_language locale to 'en')
				# from google.cloud import translate_v2 as translate

				translation = translate_client.translate(desc, target_language='en',format_='text')
				translated_text = translation['translatedText']
			print(translated_text)

			# if there is response data save the original text read from the image, 
			# the locale, translated text, and filename
			if len(response.text_annotations) > 0:
				rows_for_bq.append((desc, locale, translated_text, file.name))

	print('Writing Vision API image data to BigQuery...')
	# Write original text, locale and translated text to BQ
	# TBD: When the script is working uncomment the next line to upload results to BigQuery
	errors = bq_client.insert_rows(table, rows_for_bq)
	assert errors == []
	```
	```bash
	python3 analyze-images.py $PROJECT_ID $BUCKET_NAME
	```
- Step 5: Run the query in BigQuery Editor
	```sql
	SELECT locale,COUNT(locale) as lcount FROM image_classification_dataset.image_text_detail GROUP BY locale ORDER BY lcount DESC
	```
