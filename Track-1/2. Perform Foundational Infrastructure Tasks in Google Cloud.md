## Contents
1. [Cloud Storage (Qwik Start)](#Cloud%20Storage%20(Qwik%20Start))
2. [Cloud IAM (Qwik Start)](#Cloud%20IAM%20(Qwik%20Start))
3. [Cloud Functions (Qwik Start)](#Cloud%20Functions%20(Qwik%20Start))
4. [Google Cloud Pub/Sub (Qwik Start)](#Google%20Cloud%20Pub/Sub%20(Qwik%20Start))
5. [Challenge Lab](#Challenge%20Lab)
---
#### Cloud Storage (Qwik Start)
- Bucket command
	```bash
	# export bucket name as env variable
	# export BUCKET_NAME=<your-unique-name>
	export BUCKET_NAME=gse_cloud
	#
	# create a bucket
	# -c -> class ie standard/nearline/..
	# -l -> location
	# -b -> on/off on=uniform access control, off(default):fine grained
	# --pap=unspecified/enforce prevent public access box
	# gsutil mb gs://$BUCKET_NAME/
	gsutil mb -c standard -l us-east1 gs://$BUCKET_NAME/
	#
	# download the file
	wget --output-document ada.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Ada_Lovelace_portrait.jpg/800px-Ada_Lovelace_portrait.jpg
	#
	# copy the file to the bucket
	# gsutil cp ada.jpg gs://YOUR-BUCKET-NAME
	gsutil cp ada.jpg gs://gse_cloud
	#
	# remove the image
	rm ada.jpg
	#
	# download the object from the bucket
	# gsutil cp -r gs://YOUR-BUCKET-NAME/<file_path>
	gsutil cp -r gs://gse_cloud/ada.jpg
	#
	# copy an object to a folder in the bucket
	# gsutil cp gs://YOUR-BUCKET-NAME/<file_path> gs://YOUR-BUCKET-NAME/<folder_path>/
	gsutil cp gs://gse_cloud/ada.jpg gs://gse_cloud/image-folder/
	#
	# list contents of the bucket or folder
	# gsutil ls gs://YOUR-BUCKET-NAME
	gsutil ls gs://gse_cloud
	#
	# list details of an object
	# gsutil ls -l gs://YOUR-BUCKET-NAME/<file_path>
	gsutil ls -l gs://gse_cloud/ada.jpg
	#
	# make your object publicly accessible
	# gsutil acl ch -u AllUsers:R gs://YOUR-BUCKET-NAME/<file_path>
	gsutil acl ch -u AllUsers:R gs://gse_cloud/ada.jpg
	#
	# remove public access
	# gsutil acl ch -d AllUsers gs://YOUR-BUCKET-NAME/<file_path>
	gsutil acl ch -d AllUsers gs://gse_cloud/ada.jpg
	#
	# delete objects
	# gsutil rm gs://YOUR-BUCKET-NAME/<file_path>
	gsutil rm gs://gse_cloud/ada.jpg
	```
---
#### Cloud IAM (Qwik Start)
```bash
# get the current access to the particular resource-type
# RESOURCE_ID like GCP PROJECT_ID
# FORMAT like json/yaml
# PATH where you have to store the policy file
# gcloud [RESOURCE_TYPE=projects/resource-manager/folders/organizations] get-iam-policy RESOURCE_ID --format=FORMAT > PATH
gcloud projects get-iam-policy my-project --format=json > ~/policy.json
#
# grant a single role
# gcloud RESOURCE_TYPE add-iam-policy-binding RESOURCE_ID --member=PRINCIPAL --role=ROLE_ID --condition=CONDITION
gcloud projects add-iam-policy-binding my-project --member=user:my-user@example.com --role=roles/resourcemanager.projectCreator
#
# revoke any role
# gcloud RESOURCE_TYPE remove-iam-policy-binding RESOURCE_ID --member=PRINCIPAL --role=ROLE_ID
gcloud projects remove-iam-policy-binding my-project --member=user:my-user@example.com --role=roles/resourcemanager.projectCreator
#
# to modify many roles
# get the policy for that RESOURCE
# then mody that json/yaml file
# then set the updated file as policy
# gcloud RESOURCE_TYPE set-iam-policy RESOURCE_ID PATH
gcloud projects set-iam-policy my-project ~/policy.json
```
```bash
# for the lab
# start
# in cloud shell of user1
# export the bucket name
export BUCKET_NAME=<NAME>
#
# export the project id
export PROJECT_ID=<PROJECT_ID>
#
# export both the username
export USER1=<USERNAME1>
export USER2=<USERNAME2>
#
# create a bucket
gsutil mb gs://$BUCKET_NAME
#
# create a file sample.txt
cat > sample.txt << EOF
hi
EOF
#
# upload the file in the bucket
gsutil cp sample.txt gs://$BUCKET_NAME
#
# revoke the role of the second user
gcloud projects remove-iam-policy-binding $PROJECT_ID --member=user:$USER2 --role=roles/viewer
#
# add the user2 with different permission
gcloud projects add-iam-policy-binding $PROJECT_ID --member=user:$USER2 --role=roles/storage.objectViewer
# end

```
```bash
# for the lab
# start
# in cloud shell of user2
# export the bucket name
export BUCKET_NAME=<NAME>
#
# search the contents of the bucket
gsutil ls gs://$BUCKET_NAME
#
# end

```
---
#### Cloud Functions (Qwik Start)
```bash
# create or update a google cloud function
# gcloud functions deploy (NAME: --region=REGION) [--allow-unauthenticated] [--egress-settings=EGRESS_SETTINGS] [--entry-point=ENTRY_POINT] [--ignore-file=IGNORE_FILE] [--ingress-settings=INGRESS_SETTINGS] [--memory=MEMORY] [--retry] [--runtime=RUNTIME] [--security-level=SECURITY_LEVEL] [--service-account=SERVICE_ACCOUNT] [--source=SOURCE] [--stage-bucket=STAGE_BUCKET] [--timeout=TIMEOUT] [--update-labels=[KEY=VALUE,…]] [--build-env-vars-file=FILE_PATH | --clear-build-env-vars] | --set-build-env-vars=[KEY=VALUE,…] | --remove-build-env-vars=[KEY,…] --update-build-env-vars=[KEY=VALUE,…]] [--build-worker-pool=BUILD_WORKER_POOL | --clear-build-worker-pool] [--clear-env-vars | --env-vars-file=FILE_PATH | --set-env-vars=[KEY=VALUE,…] | --remove-env-vars=[KEY,…] --update-env-vars=[KEY=VALUE,…]] [--clear-labels | --remove-labels=[KEY,…]] [--clear-max-instances | --max-instances=MAX_INSTANCES] [--clear-vpc-connector | --vpc-connector=VPC_CONNECTOR] [--trigger-bucket=TRIGGER_BUCKET | --trigger-http | --trigger-topic=TRIGGER_TOPIC  | --trigger-event=EVENT_TYPE | --trigger-resource=RESOURCE] [GCLOUD_WIDE_FLAG …]
gcloud functions deploy helloWorld --stage-bucket=$BUCKET_NAME --trigger-topic=hello_world --runtime=nodejs12
#
# verify the function
# gcloud functions describe (NAME: --region=REGION) [GCLOUD_WIDE_FLAG…]
gcloud functions describe helloWorld
#
# view logs to see your message
# gcloud functions logs COMMAND [GCLOUD_WIDE_FLAG …]
gcloud functions logs read helloWorld

```
---
#### Google Cloud Pub/Sub (Qwik Start)


---
#### Challenge Lab
- Step 1:
	```bash
	# start
	# export the BUCKET_NAME
	export BUCKET_NAME=gse_lab_cloud
	#
	#
	# create a bucket
	gsutil mb -l us-east1 gs://$BUCKET_NAME
	#
	# end
	
	```

- Step 2:
	```bash
	# start
	# create a pub/sub topic
	gcloud pubsub topics create gseLab
	#
	# end
	
	```

- Step 3:
	```bash
	# start
	# create a index.js
	# check whether value of topicName is same as the topic you have created
	cat > index.js << EOF
	/* globals exports, require */
	//jshint strict: false
	//jshint esversion: 6
	"use strict";
	const crc32 = require("fast-crc32c");
	const { Storage } = require('@google-cloud/storage');
	const gcs = new Storage();
	const { PubSub } = require('@google-cloud/pubsub');
	const imagemagick = require("imagemagick-stream");
	exports.thumbnail = (event, context) => {
	  const fileName = event.name;
	  const bucketName = event.bucket;
	  const size = "64x64"
	  const bucket = gcs.bucket(bucketName);
	  const topicName = "gseLab";
	  const pubsub = new PubSub();
	  if ( fileName.search("64x64_thumbnail") == -1 ){
		// doesn\'t have a thumbnail, get the filename extension
		var filename_split = fileName.split('.');
		var filename_ext = filename_split[filename_split.length - 1];
		var filename_without_ext = fileName.substring(0, fileName.length - filename_ext.length );
		if (filename_ext.toLowerCase() == 'png' || filename_ext.toLowerCase() == 'jpg'){
		  // only support png and jpg at this point
		  console.log(`Processing Original: gs://${bucketName}/${fileName}`);
		  const gcsObject = bucket.file(fileName);
		  let newFilename = filename_without_ext + size + '_thumbnail.' + filename_ext;
		  let gcsNewObject = bucket.file(newFilename);
		  let srcStream = gcsObject.createReadStream();
		  let dstStream = gcsNewObject.createWriteStream();
		  let resize = imagemagick().resize(size).quality(90);
		  srcStream.pipe(resize).pipe(dstStream);
		  return new Promise((resolve, reject) => {
			dstStream
			  .on("error", (err) => {
				console.log(`Error: ${err}`);
				reject(err);
			  })
			  .on("finish", () => {
				console.log(`Success: ${fileName} → ${newFilename}`);
				  // set the content-type
				  gcsNewObject.setMetadata(
				  {
					contentType: 'image/'+ filename_ext.toLowerCase()
				  }, function(err, apiResponse) {});
				  pubsub
					.topic(topicName)
					.publisher()
					.publish(Buffer.from(newFilename))
					.then(messageId => {
					  console.log(`Message ${messageId} published.`);
					})
					.catch(err => {
					  console.error('ERROR:', err);
					});
			  });
		  });
		}
		else {
		  console.log(`gs://${bucketName}/${fileName} is not an image I can handle`);
		}
	  }
	  else {
		console.log(`gs://${bucketName}/${fileName} already has a thumbnail`);
	  }
	};
	EOF
	#
	# create a package.json
	cat > package.json << EOF
	{
	  "name": "thumbnails",
	  "version": "1.0.0",
	  "description": "Create Thumbnail of uploaded image",
	  "scripts": {
		"start": "node index.js"
	  },
	  "dependencies": {
		"@google-cloud/functions-framework": "^1.1.1",
		"@google-cloud/pubsub": "^2.0.0",
		"@google-cloud/storage": "^5.0.0",
		"fast-crc32c": "1.0.4",
		"imagemagick-stream": "4.1.1"
	  },
	  "devDependencies": {},
	  "engines": {
		"node": ">=4.3.2"
	  }
	}
	EOF
	#
	# deploy the function
	gcloud functions deploy cloudFuntion --entry-point=thumbnail --runtime=nodejs12 --stage-bucket=$BUCKET_NAME --trigger-resource=$BUCKET_NAME --trigger-event=google.storage.object.finalize
	#
	# download the file
	wget --output-document map.jpg https://storage.googleapis.com/cloud-training/gsp315/map.jpg
	#
	# upload the file on the bucket
	gsutil cp map.jpg gs://$BUCKET_NAME
	#
	# end
	
	```
- Step 4:
	```bash
	# start
	# export the project id
	export PROJECT_ID=<PROJECT_ID>
	#
	# get the policy of the project
	gcloud projects get-iam-policy $PROJECT_ID --format=json > policy.json
	#
	# view the json
	cat policy.json
	#
	# check the members having "role": "roles/viewer"
	# copy the other user name 
	# in my case it was 'student-04-f3a624891870@qwiklabs.net'
	gcloud projects remove-iam-policy-binding $PROJECT_ID --member=user:student-04-f3a624891870@qwiklabs.net --role=roles/viewer
	#
	# end
	
	```
